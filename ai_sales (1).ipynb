{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/akshatsharma/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/akshatsharma/Library/Python/3.9/lib/python/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the AI-Driven Sales Assistant!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Speech Analysis]\n",
      "Detected Sentiment: POSITIVE (Confidence: 1.00)\n",
      "\n",
      "[Product Recommendations]\n",
      "Customer not found in CRM.\n",
      "\n",
      "[Objection Handling Prompt]\n",
      "Prompt: How to handle this objection: yes bro.\n",
      "\n",
      "I'm not sure if you're aware of the fact that the \"I'm not sure if you're aware of the fact that the \"I'm not sure if you're aware of the fact\n",
      "\n",
      "[Post-Call Summary]\n",
      "Summary: Customer expressed concerns about pricing. Suggested offering a discount.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline, GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "# 1. Real-Time Speech Analysis and Sentiment Detection\n",
    "sentiment_analyzer = pipeline(\"sentiment-analysis\")\n",
    "\n",
    "def analyze_speech(speech):\n",
    "    result = sentiment_analyzer(speech)\n",
    "    sentiment = result[0][\"label\"]\n",
    "    confidence = result[0][\"score\"]\n",
    "    print(f\"\\n[Speech Analysis]\")\n",
    "    print(f\"Detected Sentiment: {sentiment} (Confidence: {confidence:.2f})\")\n",
    "    return sentiment, confidence\n",
    "\n",
    "\n",
    "# 2. CRM-Integrated Product Recommendation System\n",
    "crm_data = {\n",
    "    \"John Doe\": {\"past_purchases\": [\"Laptop\"], \"interests\": [\"Electronics\", \"Gaming\"]},\n",
    "    \"Jane Smith\": {\"past_purchases\": [\"Running Shoes\"], \"interests\": [\"Fitness\", \"Sports\"]}\n",
    "}\n",
    "\n",
    "def recommend_product(customer_name):\n",
    "    print(\"\\n[Product Recommendations]\")\n",
    "    if customer_name in crm_data:\n",
    "        customer = crm_data[customer_name]\n",
    "        recommendations = f\"Based on your interests in {customer['interests']}, we recommend checking out Gaming Headsets and Laptops!\"\n",
    "        print(recommendations)\n",
    "    else:\n",
    "        recommendations = \"Customer not found in CRM.\"\n",
    "        print(recommendations)\n",
    "    return recommendations\n",
    "\n",
    "\n",
    "# 3. Dynamic Question and Objection Handling Prompt Generator\n",
    "model_name = \"gpt2\"  # Use GPT-3 or GPT-4 in real implementation\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "\n",
    "def generate_prompt(objection):\n",
    "    print(\"\\n[Objection Handling Prompt]\")\n",
    "    input_text = f\"How to handle this objection: {objection}\"\n",
    "    input_ids = tokenizer.encode(input_text, return_tensors=\"pt\")\n",
    "    outputs = model.generate(input_ids, max_length=50, num_return_sequences=1)\n",
    "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    print(f\"Prompt: {generated_text}\")\n",
    "    return generated_text\n",
    "\n",
    "\n",
    "# 4. Post-Call Summary and Insight Generation Module\n",
    "def generate_summary(speech_transcript):\n",
    "    print(\"\\n[Post-Call Summary]\")\n",
    "    # Mock summary generator\n",
    "    summary = f\"Summary: Customer expressed concerns about pricing. Suggested offering a discount.\"\n",
    "    print(summary)\n",
    "    return summary\n",
    "\n",
    "\n",
    "# Main Flow\n",
    "def ai_sales_assistant():\n",
    "    print(\"Welcome to the AI-Driven Sales Assistant!\")\n",
    "\n",
    "    # Input customer name\n",
    "    customer_name = input(\"\\nEnter customer name: \")\n",
    "\n",
    "    # Simulated sales call speech\n",
    "    speech = input(\"\\nEnter customer speech: \")\n",
    "\n",
    "    # Step 1: Analyze Speech Sentiment\n",
    "    sentiment, confidence = analyze_speech(speech)\n",
    "\n",
    "    # Step 2: Provide Product Recommendations\n",
    "    recommend_product(customer_name)\n",
    "\n",
    "    # Step 3: Generate Question and Objection Handling Prompt\n",
    "    generate_prompt(speech)\n",
    "\n",
    "    # Step 4: Generate Post-Call Summary\n",
    "    generate_summary(speech)\n",
    "\n",
    "\n",
    "# Run the assistant\n",
    "ai_sales_assistant()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.48.1-py3-none-any.whl (9.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 9.7 MB 8.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting torch\n",
      "  Downloading torch-2.5.1-cp39-none-macosx_11_0_arm64.whl (63.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 63.9 MB 11.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting numpy>=1.17\n",
      "  Downloading numpy-2.0.2-cp39-cp39-macosx_14_0_arm64.whl (5.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 5.3 MB 17.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tqdm>=4.27\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "\u001b[K     |████████████████████████████████| 78 kB 11.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tokenizers<0.22,>=0.21\n",
      "  Downloading tokenizers-0.21.0-cp39-abi3-macosx_11_0_arm64.whl (2.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.6 MB 12.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /Users/akshatsharma/Library/Python/3.9/lib/python/site-packages (from transformers) (24.2)\n",
      "Collecting regex!=2019.12.17\n",
      "  Downloading regex-2024.11.6-cp39-cp39-macosx_11_0_arm64.whl (284 kB)\n",
      "\u001b[K     |████████████████████████████████| 284 kB 9.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pyyaml>=5.1\n",
      "  Downloading PyYAML-6.0.2-cp39-cp39-macosx_11_0_arm64.whl (172 kB)\n",
      "\u001b[K     |████████████████████████████████| 172 kB 31.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting filelock\n",
      "  Downloading filelock-3.16.1-py3-none-any.whl (16 kB)\n",
      "Collecting safetensors>=0.4.1\n",
      "  Downloading safetensors-0.5.2-cp38-abi3-macosx_11_0_arm64.whl (408 kB)\n",
      "\u001b[K     |████████████████████████████████| 408 kB 39.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting requests\n",
      "  Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "\u001b[K     |████████████████████████████████| 64 kB 16.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting huggingface-hub<1.0,>=0.24.0\n",
      "  Downloading huggingface_hub-0.27.1-py3-none-any.whl (450 kB)\n",
      "\u001b[K     |████████████████████████████████| 450 kB 41.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting networkx\n",
      "  Downloading networkx-3.2.1-py3-none-any.whl (1.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.6 MB 26.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting sympy==1.13.1\n",
      "  Downloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 6.2 MB 68.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting jinja2\n",
      "  Downloading jinja2-3.1.5-py3-none-any.whl (134 kB)\n",
      "\u001b[K     |████████████████████████████████| 134 kB 21.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=4.8.0 in /Users/akshatsharma/Library/Python/3.9/lib/python/site-packages (from torch) (4.12.2)\n",
      "Collecting fsspec\n",
      "  Downloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
      "\u001b[K     |████████████████████████████████| 183 kB 35.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting mpmath<1.4,>=1.1.0\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[K     |████████████████████████████████| 536 kB 50.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting MarkupSafe>=2.0\n",
      "  Downloading MarkupSafe-3.0.2-cp39-cp39-macosx_11_0_arm64.whl (12 kB)\n",
      "Collecting idna<4,>=2.5\n",
      "  Downloading idna-3.10-py3-none-any.whl (70 kB)\n",
      "\u001b[K     |████████████████████████████████| 70 kB 15.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting certifi>=2017.4.17\n",
      "  Downloading certifi-2024.12.14-py3-none-any.whl (164 kB)\n",
      "\u001b[K     |████████████████████████████████| 164 kB 34.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting charset-normalizer<4,>=2\n",
      "  Downloading charset_normalizer-3.4.1-cp39-cp39-macosx_10_9_universal2.whl (197 kB)\n",
      "\u001b[K     |████████████████████████████████| 197 kB 50.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting urllib3<3,>=1.21.1\n",
      "  Downloading urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
      "\u001b[K     |████████████████████████████████| 128 kB 34.9 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: urllib3, idna, charset-normalizer, certifi, tqdm, requests, pyyaml, fsspec, filelock, mpmath, MarkupSafe, huggingface-hub, tokenizers, sympy, safetensors, regex, numpy, networkx, jinja2, transformers, torch\n",
      "Successfully installed MarkupSafe-3.0.2 certifi-2024.12.14 charset-normalizer-3.4.1 filelock-3.16.1 fsspec-2024.12.0 huggingface-hub-0.27.1 idna-3.10 jinja2-3.1.5 mpmath-1.3.0 networkx-3.2.1 numpy-2.0.2 pyyaml-6.0.2 regex-2024.11.6 requests-2.32.3 safetensors-0.5.2 sympy-1.13.1 tokenizers-0.21.0 torch-2.5.1 tqdm-4.67.1 transformers-4.48.1 urllib3-2.3.0\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 24.3.1 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected Sentiment: POSITIVE (Confidence: 1.00)\n",
      "Analyzing: \"I'm not sure if I want this product. It seems too expensive.\"\n",
      "Detected Sentiment: NEGATIVE (Confidence: 1.00)\n",
      "--------------------------------------------------\n",
      "Analyzing: \"This product is amazing! I can't wait to use it.\"\n",
      "Detected Sentiment: POSITIVE (Confidence: 1.00)\n",
      "--------------------------------------------------\n",
      "Analyzing: \"I'm really disappointed with the quality of this item.\"\n",
      "Detected Sentiment: NEGATIVE (Confidence: 1.00)\n",
      "--------------------------------------------------\n",
      "Analyzing: \"Can you tell me more about this feature? It sounds interesting.\"\n",
      "Detected Sentiment: POSITIVE (Confidence: 1.00)\n",
      "--------------------------------------------------\n",
      "Analyzing: \"The price seems fair, but I still need to think about it.\"\n",
      "Detected Sentiment: NEGATIVE (Confidence: 0.50)\n",
      "--------------------------------------------------\n",
      "Analyzing: \"I don't trust this brand based on my past experience.\"\n",
      "Detected Sentiment: NEGATIVE (Confidence: 1.00)\n",
      "--------------------------------------------------\n",
      "Analyzing: \"Wow, this is exactly what I've been looking for!\"\n",
      "Detected Sentiment: POSITIVE (Confidence: 1.00)\n",
      "--------------------------------------------------\n",
      "Analyzing: \"I think I might go for a competitor's product instead.\"\n",
      "Detected Sentiment: NEGATIVE (Confidence: 1.00)\n",
      "--------------------------------------------------\n",
      "Analyzing: \"I'm thrilled with the service I've received so far!\"\n",
      "Detected Sentiment: POSITIVE (Confidence: 1.00)\n",
      "--------------------------------------------------\n",
      "Analyzing: \"I'm feeling overwhelmed by the options. Can you simplify it for me?\"\n",
      "Detected Sentiment: POSITIVE (Confidence: 0.70)\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Sentiment analysis pipeline\n",
    "sentiment_analyzer = pipeline(\"sentiment-analysis\")\n",
    "\n",
    "def analyze_speech(speech):\n",
    "    result = sentiment_analyzer(speech)\n",
    "    sentiment = result[0][\"label\"]\n",
    "    confidence = result[0][\"score\"]\n",
    "    print(f\"Detected Sentiment: {sentiment} (Confidence: {confidence:.2f})\")\n",
    "    return sentiment, confidence\n",
    "\n",
    "# Example input\n",
    "speech = \"I'm very much sure that I want this product\"\n",
    "analyze_speech(speech)\n",
    "\n",
    "# Example speech inputs and sentiment analysis\n",
    "speech_examples = [\n",
    "    \"I'm not sure if I want this product. It seems too expensive.\",\n",
    "    \"This product is amazing! I can't wait to use it.\",\n",
    "    \"I'm really disappointed with the quality of this item.\",\n",
    "    \"Can you tell me more about this feature? It sounds interesting.\",\n",
    "    \"The price seems fair, but I still need to think about it.\",\n",
    "    \"I don't trust this brand based on my past experience.\",\n",
    "    \"Wow, this is exactly what I've been looking for!\",\n",
    "    \"I think I might go for a competitor's product instead.\",\n",
    "    \"I'm thrilled with the service I've received so far!\",\n",
    "    \"I'm feeling overwhelmed by the options. Can you simplify it for me?\"\n",
    "]\n",
    "\n",
    "# Analyze each speech input\n",
    "for speech in speech_examples:\n",
    "    print(f\"Analyzing: \\\"{speech}\\\"\")\n",
    "    analyze_speech(speech)\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on your interests in ['Electronics', 'Gaming'], we recommend these products!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Based on your interests in ['Electronics', 'Gaming'], we recommend these products!\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mock CRM data\n",
    "crm_data = {\n",
    "    \"John Doe\": {\"past_purchases\": [\"Laptop\"], \"interests\": [\"Electronics\", \"Gaming\"]},\n",
    "    \"Jane Smith\": {\"past_purchases\": [\"Running Shoes\"], \"interests\": [\"Fitness\", \"Sports\"]}\n",
    "}\n",
    "\n",
    "def recommend_product(customer_name):\n",
    "    if customer_name in crm_data:\n",
    "        customer = crm_data[customer_name]\n",
    "        recommendations = f\"Based on your interests in {customer['interests']}, we recommend these products!\"\n",
    "        print(recommendations)\n",
    "    else:\n",
    "        print(\"Customer not found in CRM.\")\n",
    "    return recommendations\n",
    "\n",
    "# Example usage\n",
    "recommend_product(\"John Doe\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: How to handle this objection: This product is too expensive.\n",
      "\n",
      "The problem is that the price of this product is too high.\n",
      "\n",
      "The problem is that the price of this product is too high.\n",
      "\n",
      "The problem is that the price\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "# Load pre-trained model and tokenizer\n",
    "model_name = \"gpt2\"  # Use GPT-3 in real implementation\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "\n",
    "def generate_prompt(objection):\n",
    "    input_text = f\"How to handle this objection: {objection}\"\n",
    "    input_ids = tokenizer.encode(input_text, return_tensors=\"pt\")\n",
    "    outputs = model.generate(input_ids, max_length=50, num_return_sequences=1)\n",
    "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    print(f\"Prompt: {generated_text}\")\n",
    "\n",
    "# Example usage\n",
    "objection = \"This product is too expensive.\"\n",
    "generate_prompt(objection)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary: Customer expressed concerns about pricing. Suggested offering a discount.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Summary: Customer expressed concerns about pricing. Suggested offering a discount.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_summary(speech_transcript):\n",
    "    # Mock summary generator\n",
    "    summary = f\"Summary: Customer expressed concerns about pricing. Suggested offering a discount.\"\n",
    "    print(summary)\n",
    "    return summary\n",
    "\n",
    "# Example usage\n",
    "speech_transcript = \"The customer is worried about the cost of this product.\"\n",
    "generate_summary(speech_transcript)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Customer Speech: The customer is worried about the cost of this product.\n",
      "Summary: Customer expressed concerns about pricing. Suggested offering a discount or explaining financing options.\n",
      "\n",
      "Customer Speech: The customer is asking about the delivery timeline for the product.\n",
      "Summary: Customer was concerned about delivery timelines. Recommended expediting shipping or providing a tracking option.\n",
      "\n",
      "Customer Speech: The customer wants to know more about the features of the product.\n",
      "Summary: Customer had questions about product features. Suggested sharing a detailed brochure or demo.\n",
      "\n",
      "Customer Speech: The customer mentioned that a competitor's product is cheaper.\n",
      "Summary: Customer compared the product with a competitor. Highlighted unique selling points and value-added services.\n",
      "\n",
      "Customer Speech: The customer is concerned about the after-sales support for this product.\n",
      "Summary: Customer inquired about after-sales support. Reassured with details about warranty and customer support services.\n",
      "\n",
      "Customer Speech: The customer said they are working with a limited budget.\n",
      "Summary: Customer mentioned budget constraints. Suggested discussing payment plans or recommending a more affordable option.\n",
      "\n",
      "Customer Speech: The customer raised concerns about the reliability of the product.\n",
      "Summary: Customer was concerned about product quality. Shared testimonials and warranty information for reassurance.\n",
      "\n",
      "Customer Speech: The customer asked general questions without specific objections.\n",
      "Summary: General discussion about the product. No major concerns noted. Follow-up scheduled for further engagement.\n"
     ]
    }
   ],
   "source": [
    "def generate_summary(speech_transcript):\n",
    "    # Analyze the transcript and return a mock summary\n",
    "    if \"cost\" in speech_transcript or \"price\" in speech_transcript:\n",
    "        summary = \"Summary: Customer expressed concerns about pricing. Suggested offering a discount or explaining financing options.\"\n",
    "    elif \"delivery\" in speech_transcript or \"time\" in speech_transcript:\n",
    "        summary = \"Summary: Customer was concerned about delivery timelines. Recommended expediting shipping or providing a tracking option.\"\n",
    "    elif \"features\" in speech_transcript or \"functionality\" in speech_transcript:\n",
    "        summary = \"Summary: Customer had questions about product features. Suggested sharing a detailed brochure or demo.\"\n",
    "    elif \"comparison\" in speech_transcript or \"competitor\" in speech_transcript:\n",
    "        summary = \"Summary: Customer compared the product with a competitor. Highlighted unique selling points and value-added services.\"\n",
    "    elif \"support\" in speech_transcript or \"after-sales\" in speech_transcript:\n",
    "        summary = \"Summary: Customer inquired about after-sales support. Reassured with details about warranty and customer support services.\"\n",
    "    elif \"budget\" in speech_transcript or \"affordability\" in speech_transcript:\n",
    "        summary = \"Summary: Customer mentioned budget constraints. Suggested discussing payment plans or recommending a more affordable option.\"\n",
    "    elif \"quality\" in speech_transcript or \"reliability\" in speech_transcript:\n",
    "        summary = \"Summary: Customer was concerned about product quality. Shared testimonials and warranty information for reassurance.\"\n",
    "    else:\n",
    "        summary = \"Summary: General discussion about the product. No major concerns noted. Follow-up scheduled for further engagement.\"\n",
    "    \n",
    "    print(summary)\n",
    "    return summary\n",
    "\n",
    "\n",
    "# Example Usage\n",
    "transcripts = [\n",
    "    \"The customer is worried about the cost of this product.\",\n",
    "    \"The customer is asking about the delivery timeline for the product.\",\n",
    "    \"The customer wants to know more about the features of the product.\",\n",
    "    \"The customer mentioned that a competitor's product is cheaper.\",\n",
    "    \"The customer is concerned about the after-sales support for this product.\",\n",
    "    \"The customer said they are working with a limited budget.\",\n",
    "    \"The customer raised concerns about the reliability of the product.\",\n",
    "    \"The customer asked general questions without specific objections.\"\n",
    "]\n",
    "\n",
    "for transcript in transcripts:\n",
    "    print(\"\\nCustomer Speech:\", transcript)\n",
    "    generate_summary(transcript)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Objection: This product is too expensive.\n",
      "Prompt: How to handle this objection: This product is too expensive.\n",
      "\n",
      "The problem is that the price of this product has been rising for years. The price is rising because of the fact that it is a product that is not only expensive, but also\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Objection: I don't think I need this product.\n",
      "Prompt: How to handle this objection: I don't think I need this product. I just want to know what it is.\n",
      "\n",
      "I'm not sure if I should have bought it. It's not a good product, and I'm sure it's\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Objection: I am worried about the quality of the product.\n",
      "Prompt: How to handle this objection: I am worried about the quality of the product. I have been using this product for about a year now and I can tell you that it is not as good as I expected. The only thing I would change is to\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Objection: I don't have enough information to decide.\n",
      "Prompt: How to handle this objection: I don't have enough information to decide.\n",
      "\n",
      "I'm not sure if this is a good idea or not. I'm sure that it's not a bad idea. But I think it is important to understand that\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Objection: Your competitor offers a better price.\n",
      "Prompt: How to handle this objection: Your competitor offers a better price.\n",
      "\n",
      "The problem is that you're not paying for the service. You're paying the price for it. And you can't afford to pay for a service that's not available to\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Objection: The delivery time is too long.\n",
      "Prompt: How to handle this objection: The delivery time is too long.\n",
      "\n",
      "The delivery times are too short. The time to deliver is not too fast. It is a long time. You can't get it to you. If you want to get\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Objection: I am not sure this fits my needs.\n",
      "Prompt: How to handle this objection: I am not sure this fits my needs. I have a lot of experience with the use of the word \"disgusting\" in the context of a sexual encounter. It is not a word that I use often,\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Objection: I need to consult my team before deciding.\n",
      "Prompt: How to handle this objection: I need to consult my team before deciding.\n",
      "\n",
      "I'm not sure if this is a good idea or not. I'm sure that it's not a bad idea. But I don't think it is. It\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Objection: I’ve had a bad experience with similar products.\n",
      "Prompt: How to handle this objection: I’ve had a bad experience with similar products. I have tried many different brands, and none of them are as good as the one I bought.\n",
      "\n",
      "I have also tried a few different products, but\n",
      "\n",
      "\n",
      "Objection: I don’t see the value in this product.\n",
      "Prompt: How to handle this objection: I don’t see the value in this product. I‖ve been using it for a while now and I have never had any problems with it. It is a great product and it is very easy to\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "# Load pre-trained model and tokenizer\n",
    "model_name = \"gpt2\"  # Replace with \"gpt-3\" or other advanced models in a real implementation\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "\n",
    "def generate_prompt(objection):\n",
    "    \"\"\"\n",
    "    Generates a response to handle customer objections based on the input objection.\n",
    "\n",
    "    Parameters:\n",
    "    objection (str): Customer's objection or concern.\n",
    "\n",
    "    Returns:\n",
    "    str: AI-generated response for handling the objection.\n",
    "    \"\"\"\n",
    "    input_text = f\"How to handle this objection: {objection}\"\n",
    "    input_ids = tokenizer.encode(input_text, return_tensors=\"pt\")\n",
    "    outputs = model.generate(input_ids, max_length=50, num_return_sequences=1, no_repeat_ngram_size=2)\n",
    "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    print(f\"\\nObjection: {objection}\")\n",
    "    print(f\"Prompt: {generated_text}\\n\")\n",
    "    return generated_text\n",
    "\n",
    "# Example objections\n",
    "objections = [\n",
    "    \"This product is too expensive.\",\n",
    "    \"I don't think I need this product.\",\n",
    "    \"I am worried about the quality of the product.\",\n",
    "    \"I don't have enough information to decide.\",\n",
    "    \"Your competitor offers a better price.\",\n",
    "    \"The delivery time is too long.\",\n",
    "    \"I am not sure this fits my needs.\",\n",
    "    \"I need to consult my team before deciding.\",\n",
    "    \"I’ve had a bad experience with similar products.\",\n",
    "    \"I don’t see the value in this product.\"\n",
    "]\n",
    "\n",
    "# Generate prompts for each objection\n",
    "for objection in objections:\n",
    "    generate_prompt(objection)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello John Doe, based on your past purchases (Laptop) and interests in Electronics, Gaming, we recommend the following products:\n",
      "Gaming Headset, Mechanical Keyboard, Gaming Console, VR Headset\n",
      "Hello Jane Smith, based on your past purchases (Running Shoes) and interests in Fitness, Sports, we recommend the following products:\n",
      "Yoga Mat, Resistance Bands, Football, Tennis Racket\n",
      "Hello Alice Johnson, based on your past purchases (Smartphone) and interests in Photography, Travel, we recommend the following products:\n",
      "DSLR Camera, Tripod, Travel Backpack, Noise-Cancelling Headphones\n",
      "Hello Bob Brown, based on your past purchases (Kitchen Blender) and interests in Cooking, Health, we recommend the following products:\n",
      "Air Fryer, Chef's Knife, Blender Bottles, Vitamin Supplements\n",
      "Hello Eve Davis, based on your past purchases (Smartwatch) and interests in Tech, Fitness, we recommend the following products:\n",
      "Smart Home Devices, Wireless Earbuds, Yoga Mat, Resistance Bands\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Hello Eve Davis, based on your past purchases (Smartwatch) and interests in Tech, Fitness, we recommend the following products:\\nSmart Home Devices, Wireless Earbuds, Yoga Mat, Resistance Bands'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mock CRM data\n",
    "crm_data = {\n",
    "    \"John Doe\": {\"past_purchases\": [\"Laptop\"], \"interests\": [\"Electronics\", \"Gaming\"]},\n",
    "    \"Jane Smith\": {\"past_purchases\": [\"Running Shoes\"], \"interests\": [\"Fitness\", \"Sports\"]},\n",
    "    \"Alice Johnson\": {\"past_purchases\": [\"Smartphone\"], \"interests\": [\"Photography\", \"Travel\"]},\n",
    "    \"Bob Brown\": {\"past_purchases\": [\"Kitchen Blender\"], \"interests\": [\"Cooking\", \"Health\"]},\n",
    "    \"Eve Davis\": {\"past_purchases\": [\"Smartwatch\"], \"interests\": [\"Tech\", \"Fitness\"]},\n",
    "}\n",
    "\n",
    "def recommend_product(customer_name):\n",
    "    \"\"\"\n",
    "    Recommends products to the customer based on their past purchases and interests.\n",
    "\n",
    "    Parameters:\n",
    "    customer_name (str): Name of the customer in CRM data.\n",
    "\n",
    "    Returns:\n",
    "    str: Product recommendation message.\n",
    "    \"\"\"\n",
    "    if customer_name in crm_data:\n",
    "        customer = crm_data[customer_name]\n",
    "        past_purchases = \", \".join(customer[\"past_purchases\"])\n",
    "        interests = \", \".join(customer[\"interests\"])\n",
    "        recommendations = (\n",
    "            f\"Hello {customer_name}, based on your past purchases ({past_purchases}) \"\n",
    "            f\"and interests in {interests}, we recommend the following products:\\n\"\n",
    "        )\n",
    "        # Mock recommendations based on interests\n",
    "        interest_based_products = {\n",
    "            \"Electronics\": [\"Gaming Headset\", \"Mechanical Keyboard\"],\n",
    "            \"Gaming\": [\"Gaming Console\", \"VR Headset\"],\n",
    "            \"Fitness\": [\"Yoga Mat\", \"Resistance Bands\"],\n",
    "            \"Sports\": [\"Football\", \"Tennis Racket\"],\n",
    "            \"Photography\": [\"DSLR Camera\", \"Tripod\"],\n",
    "            \"Travel\": [\"Travel Backpack\", \"Noise-Cancelling Headphones\"],\n",
    "            \"Cooking\": [\"Air Fryer\", \"Chef's Knife\"],\n",
    "            \"Health\": [\"Blender Bottles\", \"Vitamin Supplements\"],\n",
    "            \"Tech\": [\"Smart Home Devices\", \"Wireless Earbuds\"],\n",
    "        }\n",
    "        # Compile product suggestions\n",
    "        suggested_products = []\n",
    "        for interest in customer[\"interests\"]:\n",
    "            if interest in interest_based_products:\n",
    "                suggested_products.extend(interest_based_products[interest])\n",
    "        recommendations += \", \".join(suggested_products)\n",
    "        print(recommendations)\n",
    "    else:\n",
    "        recommendations = f\"Customer {customer_name} not found in CRM.\"\n",
    "        print(recommendations)\n",
    "    return recommendations\n",
    "\n",
    "# Example usage\n",
    "recommend_product(\"John Doe\")\n",
    "recommend_product(\"Jane Smith\")\n",
    "recommend_product(\"Alice Johnson\")\n",
    "recommend_product(\"Bob Brown\")\n",
    "recommend_product(\"Eve Davis\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1. Real-Time Speech Analysis and Sentiment Detection\n",
    "What is it? This module uses NLP to analyze customer speech during a sales call and detect the sentiment, such as positive, negative, or neutral, along with a confidence score.\n",
    "Why is it used? To understand the emotional tone of the customer during a call, which helps sales representatives adjust their approach dynamically.\n",
    "Where is it used? In live sales calls to identify customer sentiment in real-time and guide conversations effectively.\n",
    "How does it work?\n",
    "The pipeline from the transformers library is used to load a sentiment analysis model.\n",
    "It evaluates the customer’s speech and outputs the sentiment with a confidence score.\n",
    "2. CRM-Integrated Product Recommendation System\n",
    "What is it? This module provides personalized product recommendations based on customer information stored in a CRM, such as past purchases and interests.\n",
    "Why is it used? To deliver tailored product suggestions, making the sales pitch more relevant and increasing the chances of conversion.\n",
    "Where is it used?\n",
    "E-commerce platforms for product recommendations.\n",
    "Sales calls to suggest products or services based on customer preferences.\n",
    "How does it work?\n",
    "The CRM data contains customer profiles with past purchases and interests.\n",
    "The module fetches customer details and suggests products aligning with their preferences.\n",
    "3. Dynamic Question and Objection Handling Prompt Generator\n",
    "What is it? This module provides context-based prompts for handling customer objections, such as price concerns or brand trust issues.\n",
    "Why is it used? To assist sales representatives in handling objections with effective strategies and maintaining customer trust.\n",
    "Where is it used?\n",
    "During sales calls when customers raise concerns or objections.\n",
    "In customer support or service calls to guide agents.\n",
    "How does it work?\n",
    "The module uses a pre-trained language model (GPT-2, GPT-3, or GPT-4) to generate tailored objection-handling prompts based on customer concerns.\n",
    "It takes the objection as input and generates a suitable response.\n",
    "4. Post-Call Summary and Insight Generation Module\n",
    "What is it? This module generates a summary of the sales call, highlighting key points such as customer concerns, recommended actions, and insights for improvement.\n",
    "Why is it used? To document the call for follow-up actions and to improve sales training by providing actionable insights.\n",
    "Where is it used?\n",
    "After sales or customer support calls to summarize the conversation.\n",
    "In training programs to analyze real-world sales scenarios and improve future strategies.\n",
    "How does it work?\n",
    "The module takes the speech transcript and uses predefined logic or models to generate a brief summary.\n",
    "It emphasizes critical aspects like customer objections and suggested resolutions.\n",
    "How These Modules Work Together in the AI Sales Assistant\n",
    "Real-Time Speech Analysis: Detects the sentiment of the customer's speech during the call.\n",
    "Product Recommendations: Suggests products based on the customer's profile, ensuring relevance.\n",
    "Objection Handling: Provides a prompt to handle customer objections effectively.\n",
    "Post-Call Summary: Generates a summary of the entire call for documentation and future reference.\n",
    "Additional Details\n",
    "Integration:\n",
    "These modules can be integrated into a live sales tool or CRM system.\n",
    "They can work independently or as part of a pipeline to enhance the sales representative's efficiency.\n",
    "Technologies Used:\n",
    "Transformers library for sentiment analysis and objection handling.\n",
    "CRM data storage for personalized recommendations.\n",
    "Simple text processing for generating call summaries.\n",
    "Future Enhancements:\n",
    "Replace GPT-2 with GPT-3 or GPT-4 for better objection handling.\n",
    "Use advanced machine learning models for more accurate sentiment detection.\n",
    "Integrate with real CRM systems and databases.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
